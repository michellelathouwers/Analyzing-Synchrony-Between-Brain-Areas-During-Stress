{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc1e525a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: multiSyncPy in c:\\users\\michelle\\software\\anaconda3\\lib\\site-packages (0.1.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\michelle\\software\\anaconda3\\lib\\site-packages (from multiSyncPy) (1.24.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\michelle\\software\\anaconda3\\lib\\site-packages (from multiSyncPy) (1.11.1)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\michelle\\software\\anaconda3\\lib\\site-packages (from multiSyncPy) (1.3.0)\n",
      "Requirement already satisfied: seaborn in c:\\users\\michelle\\software\\anaconda3\\lib\\site-packages (from multiSyncPy) (0.12.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\michelle\\appdata\\roaming\\python\\python311\\site-packages (from multiSyncPy) (3.8.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\michelle\\software\\anaconda3\\lib\\site-packages (from matplotlib->multiSyncPy) (1.0.5)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\michelle\\software\\anaconda3\\lib\\site-packages (from matplotlib->multiSyncPy) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\michelle\\software\\anaconda3\\lib\\site-packages (from matplotlib->multiSyncPy) (4.25.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\michelle\\software\\anaconda3\\lib\\site-packages (from matplotlib->multiSyncPy) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\michelle\\software\\anaconda3\\lib\\site-packages (from matplotlib->multiSyncPy) (23.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\michelle\\software\\anaconda3\\lib\\site-packages (from matplotlib->multiSyncPy) (9.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\michelle\\software\\anaconda3\\lib\\site-packages (from matplotlib->multiSyncPy) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\michelle\\software\\anaconda3\\lib\\site-packages (from matplotlib->multiSyncPy) (2.8.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\michelle\\software\\anaconda3\\lib\\site-packages (from scikit-learn->multiSyncPy) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\michelle\\software\\anaconda3\\lib\\site-packages (from scikit-learn->multiSyncPy) (2.2.0)\n",
      "Requirement already satisfied: pandas>=0.25 in c:\\users\\michelle\\software\\anaconda3\\lib\\site-packages (from seaborn->multiSyncPy) (2.2.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\michelle\\software\\anaconda3\\lib\\site-packages (from pandas>=0.25->seaborn->multiSyncPy) (2023.3.post1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\michelle\\software\\anaconda3\\lib\\site-packages (from pandas>=0.25->seaborn->multiSyncPy) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\michelle\\software\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->multiSyncPy) (1.16.0)\n",
      "done loading\n"
     ]
    }
   ],
   "source": [
    "!pip install multiSyncPy\n",
    "\n",
    "import numpy as np\n",
    "import scipy.spatial\n",
    "import scipy.signal\n",
    "import scipy.stats\n",
    "import pandas as pd\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import multiSyncPy as msp\n",
    "from multiSyncPy import synchrony_metrics as sm\n",
    "print('done loading')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4e98730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "#Takes as input a list or array of multiple time series, outputs various metrics from the multiSyncPy package\n",
    "def multiSyncPy_metrics(time_series):\n",
    "    time_series = np.array(time_series)\n",
    "    \n",
    "    coherence_team = sm.coherence_team(time_series)\n",
    "    \n",
    "    symbolic_entropy = sm.symbolic_entropy(time_series)\n",
    "    \n",
    "    phases = np.angle(scipy.signal.hilbert(time_series))\n",
    "    rho = sm.rho(phases)[1]\n",
    "    \n",
    "    recurrence_matrix = sm.recurrence_matrix(time_series, radius = 0.5)\n",
    "    rqa_metrics = sm.rqa_metrics(recurrence_matrix)\n",
    "    \n",
    "    #Not sure if the np.tile parameters are correct\n",
    "    time_series_sample = np.tile(time_series, (100, 1, 1)) + np.random.normal(0, 0.1, (100, len(time_series), len(time_series[0])))\n",
    "    time_series_sample = np.angle(scipy.signal.hilbert(time_series_sample))\n",
    "    \n",
    "    #Do we want this one to be with the rest or do we want this to be separate, because the notebook mentions \n",
    "    #that this is for specific cases\n",
    "    weak_null = sm.kuramoto_weak_null(time_series_sample)\n",
    "    return coherence_team, symbolic_entropy, rho, weak_null\n",
    "\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64844363",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n",
      "(9600,)\n"
     ]
    }
   ],
   "source": [
    "#Hypothesis 1:\n",
    "#extract relevant files Stroop fp1 and fp2\n",
    "\n",
    "stroop_files_fp1=[]\n",
    "stroop_files_fp2=[]\n",
    "\n",
    "for i in range(1,41):\n",
    "    f=pd.read_csv(\"Stroop/Stroop_sub_\"+str(i)+\".csv\")\n",
    "    stroop_files_fp1.append(f['2'])\n",
    "    stroop_files_fp2.append(f['31'])\n",
    "# print(stroop_files_fp1[0])\n",
    "# print(stroop_files_fp2[0])\n",
    "# print(len(stroop_files_fp1))\n",
    "print('done')\n",
    "print(stroop_files_fp1[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45278cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "#calculate multiSyncPy metrics Stroop H1\n",
    "coherenceList0=[]\n",
    "entropyList0=[]\n",
    "rhoList0=[]\n",
    "weakNullList0=[]\n",
    "\n",
    "for i in range(len(stroop_files_fp1)):\n",
    "    print(i)\n",
    "    inputArray = np.array((stroop_files_fp1[i], stroop_files_fp2[i]))\n",
    "    coherence, entropy, rho, weakNull = multiSyncPy_metrics(inputArray)\n",
    "    coherenceList0.append(coherence)\n",
    "    entropyList0.append(entropy)\n",
    "    rhoList0.append(rho)\n",
    "    weakNullList0.append(weakNull)\n",
    "    \n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99eb033",
   "metadata": {},
   "outputs": [],
   "source": [
    "#round lists\n",
    "\n",
    "rounded_coherence0 = [round(num, 2) for num in coherenceList0]\n",
    "rounded_entropy0 = [round(num, 2) for num in entropyList0]\n",
    "\n",
    "df_h14 = pd.DataFrame({'Participant': list(range(1,41)), 'Coherence': rounded_coherence0, 'Entropy': rounded_entropy0})\n",
    "df_h14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3420813b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert df to csv to compare in H3\n",
    "\n",
    "df_h1 = pd.DataFrame({'Participant': list(range(1,41)), 'Coherence': coherenceList0, 'Entropy': entropyList0, 'Rho': rhoList0})\n",
    "\n",
    "df_h1.to_csv('h1_stroop_fp1_fp2.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38411adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mean values for Stroop fp1 and fp2 H1\n",
    "print(\"Mean Coherence: \",np.mean(coherenceList0))\n",
    "print(\"Mean Entropy: \",np.mean(entropyList0))\n",
    "print(\"Mean Rho: \",np.mean(rhoList0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb2133f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#extract relevant files Relax H1\n",
    "relax_files_fp1=[]\n",
    "relax_files_fp2=[]\n",
    "\n",
    "for i in range(1,41):\n",
    "    \n",
    "    f=pd.read_csv(\"Relax/Relax_sub_\"+str(i)+\".csv\")\n",
    "    relax_files_fp1.append(f['2'])\n",
    "    relax_files_fp2.append(f['31'])\n",
    "# print(relax_files_fp1[0])\n",
    "# print(relax_files_fp2[0])\n",
    "# print(len(relax_files_fp1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6065bdca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate multiSyncPy metrics Relax H1\n",
    "coherenceList1=[]\n",
    "entropyList1=[]\n",
    "rhoList1=[]\n",
    "weakNullList1=[]\n",
    "\n",
    "for i in range(len(relax_files_fp1)):\n",
    "    print(i)\n",
    "    inputArray = np.array((relax_files_fp1[i], relax_files_fp2[i]))\n",
    "    print(inputArray.shape)\n",
    "    coherence, entropy, rho, weakNull = multiSyncPy_metrics(inputArray)\n",
    "    coherenceList1.append(coherence)\n",
    "    entropyList1.append(entropy)\n",
    "    rhoList1.append(rho)\n",
    "    weakNullList1.append(weakNull)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e5bb72",
   "metadata": {},
   "outputs": [],
   "source": [
    "#round lists\n",
    "\n",
    "rounded_coherence1 = [round(num, 2) for num in coherenceList1]\n",
    "rounded_entropy1 = [round(num, 2) for num in entropyList1]\n",
    "\n",
    "df_h12 = pd.DataFrame({'Participant': list(range(1,41)), 'Coherence': rounded_coherence1, 'Entropy': rounded_entropy1})\n",
    "df_h12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aceb5f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert df to csv to compare in H3\n",
    "\n",
    "df_h13 = pd.DataFrame({'Participant': list(range(1,41)), 'Coherence': coherenceList1, 'Entropy': entropyList1})\n",
    "df_h13.to_csv('h1_relax_fp1_fp2.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab15d172",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mean values for Relax fp1 and fp2 H1\n",
    "print(\"Mean Coherence: \",np.mean(coherenceList1))\n",
    "print(\"Mean Entropy: \",np.mean(entropyList1))\n",
    "print(\"Mean Rho: \",np.mean(rhoList1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b215611",
   "metadata": {},
   "outputs": [],
   "source": [
    "#significance test H1\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "t_statistic, p_value = ttest_ind(coherenceList0, coherenceList1)\n",
    "\n",
    "print('Coherence')\n",
    "print(\"t-statistic:\", t_statistic)\n",
    "print(\"p-value:\", p_value)\n",
    "\n",
    "t_statistic, p_value = ttest_ind(entropyList0, entropyList1)\n",
    "\n",
    "print()\n",
    "print('Entropy')\n",
    "print(\"t-statistic:\", t_statistic)\n",
    "print(\"p-value:\", p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af17ea13",
   "metadata": {},
   "source": [
    "# Surrogation technique 1: shuffling windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a85c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For stroop data\n",
    "\n",
    "surrogate_1_stroop_files_fp1 = []  \n",
    "surrogate_1_stroop_files_fp2 = []\n",
    "\n",
    " \n",
    "surrogate_1_stroop_fp1 = sm.shuffle_time_windows(np.array(stroop_files_fp1), 100)\n",
    "surrogate_1_stroop_fp2 = sm.shuffle_time_windows(np.array(stroop_files_fp2), 100) \n",
    "\n",
    "\n",
    "for i in surrogate_1_stroop_fp1:\n",
    "    surrogate_1_stroop_files_fp1.append(i)\n",
    "    \n",
    "for i in surrogate_1_stroop_fp2:\n",
    "    surrogate_1_stroop_files_fp2.append(i)\n",
    "    \n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ed80e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate multiSyncPy metrics Stroop H1\n",
    "coherenceList0=[]\n",
    "entropyList0=[]\n",
    "rhoList0=[]\n",
    "weakNullList0=[]\n",
    "\n",
    "for i in range(len(surrogate_1_stroop_files_fp1)):\n",
    "    print(i)\n",
    "    inputArray = np.array((surrogate_1_stroop_files_fp1[i], surrogate_1_stroop_files_fp2[i]))\n",
    "    coherence, entropy, rho, weakNull = multiSyncPy_metrics(inputArray)\n",
    "    coherenceList0.append(coherence)\n",
    "    entropyList0.append(entropy)\n",
    "    rhoList0.append(rho)\n",
    "    weakNullList0.append(weakNull)\n",
    "    \n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a30af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#round lists\n",
    "\n",
    "rounded_coherence0 = [round(num, 2) for num in coherenceList0]\n",
    "rounded_entropy0 = [round(num, 2) for num in entropyList0]\n",
    "\n",
    "df_h14 = pd.DataFrame({'Participant': list(range(1,41)), 'Coherence': rounded_coherence0, 'Entropy': rounded_entropy0})\n",
    "df_h14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb779a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert df to csv to compare in H3\n",
    "\n",
    "df_h1 = pd.DataFrame({'Participant': list(range(1,41)), 'Coherence': coherenceList0, 'Entropy': entropyList0})\n",
    "\n",
    "df_h1.to_csv('h1_surrogate1_stroop_fp1_fp2.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3caf57b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mean values for Stroop fp1 and fp2 H1\n",
    "print(\"Mean Coherence: \",np.mean(coherenceList0))\n",
    "print(\"Mean Entropy: \",np.mean(entropyList0))\n",
    "print(\"Mean Rho: \",np.mean(rhoList0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea73a3e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For relax data\n",
    "\n",
    "surrogate_1_relax_files_fp1 = []  \n",
    "surrogate_1_relax_files_fp2 = []\n",
    "\n",
    " \n",
    "surrogate_1_relax_fp1 = sm.shuffle_time_windows(np.array(relax_files_fp1), 100)\n",
    "surrogate_1_relax_fp2 = sm.shuffle_time_windows(np.array(relax_files_fp2), 100)   \n",
    "\n",
    "\n",
    "for i in surrogate_1_relax_fp1:\n",
    "    surrogate_1_relax_files_fp1.append(i)\n",
    "    \n",
    "for i in surrogate_1_stroop_fp2:\n",
    "    surrogate_1_relax_files_fp2.append(i)\n",
    "    \n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be829e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate multiSyncPy metrics Relax H1\n",
    "coherenceList0=[]\n",
    "entropyList0=[]\n",
    "rhoList0=[]\n",
    "weakNullList0=[]\n",
    "\n",
    "for i in range(len(surrogate_1_relax_files_fp1)):\n",
    "    print(i)\n",
    "    inputArray = np.array((surrogate_1_relax_files_fp1[i], surrogate_1_relax_files_fp2[i]))\n",
    "    coherence, entropy, rho, weakNull = multiSyncPy_metrics(inputArray)\n",
    "    coherenceList0.append(coherence)\n",
    "    entropyList0.append(entropy)\n",
    "    rhoList0.append(rho)\n",
    "    weakNullList0.append(weakNull)\n",
    "    \n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2545fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#round lists\n",
    "\n",
    "rounded_coherence0 = [round(num, 2) for num in coherenceList0]\n",
    "rounded_entropy0 = [round(num, 2) for num in entropyList0]\n",
    "\n",
    "df_h14 = pd.DataFrame({'Participant': list(range(1,41)), 'Coherence': rounded_coherence0, 'Entropy': rounded_entropy0})\n",
    "df_h14\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c86eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert df to csv to compare in H3\n",
    "\n",
    "df_h1 = pd.DataFrame({'Participant': list(range(1,41)), 'Coherence': coherenceList0, 'Entropy': entropyList0})\n",
    "\n",
    "df_h1.to_csv('h1_surrogate1_relax_fp1_fp2.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b95b9f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mean values for Stroop fp1 and fp2 H1\n",
    "print(\"Mean Coherence: \",np.mean(coherenceList0))\n",
    "print(\"Mean Entropy: \",np.mean(entropyList0))\n",
    "print(\"Mean Rho: \",np.mean(rhoList0))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801af53c",
   "metadata": {},
   "source": [
    "# Surrogation technique 2: Data sliding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178163b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for stroop data\n",
    "\n",
    "# Define the percentage of data to slide\n",
    "slide_percentage = 0.6\n",
    "\n",
    "# Define a function for data sliding\n",
    "def slide_data(data, slide_percentage):\n",
    "    # Determine the number of data points to slide\n",
    "    num_points_to_slide = int(len(data) * slide_percentage)\n",
    "    \n",
    "    # Slide the data\n",
    "    slid_data = np.roll(data, num_points_to_slide)\n",
    "    \n",
    "    return slid_data\n",
    "\n",
    "surrogate_2_stroop_files_fp1 = []\n",
    "surrogate_2_stroop_files_fp2 = []\n",
    "\n",
    "for data_fp1 in stroop_files_fp1:\n",
    "    slid_data = slide_data(data_fp1.values, slide_percentage)\n",
    "    surrogate_2_stroop_files_fp1.append(slid_data)\n",
    "    \n",
    "for data_fp2 in stroop_files_fp2:\n",
    "    slid_data = slide_data(data_fp2.values, slide_percentage)\n",
    "    surrogate_2_stroop_files_fp2.append(slid_data)\n",
    "    \n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "014864de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate multiSyncPy metrics Stroop H1\n",
    "coherenceList0=[]\n",
    "entropyList0=[]\n",
    "rhoList0=[]\n",
    "weakNullList0=[]\n",
    "\n",
    "for i in range(len(surrogate_2_stroop_files_fp1)):\n",
    "    print(i)\n",
    "    inputArray = np.array((surrogate_2_stroop_files_fp1[i], surrogate_2_stroop_files_fp2[i]))\n",
    "    coherence, entropy, rho, weakNull = multiSyncPy_metrics(inputArray)\n",
    "    coherenceList0.append(coherence)\n",
    "    entropyList0.append(entropy)\n",
    "    rhoList0.append(rho)\n",
    "    weakNullList0.append(weakNull)\n",
    "    \n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e8a3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#round lists\n",
    "\n",
    "rounded_coherence0 = [round(num, 2) for num in coherenceList0]\n",
    "rounded_entropy0 = [round(num, 2) for num in entropyList0]\n",
    "\n",
    "df_h14 = pd.DataFrame({'Participant': list(range(1,41)), 'Coherence': rounded_coherence0, 'Entropy': rounded_entropy0})\n",
    "df_h14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acdf2a0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert df to csv to compare in H3\n",
    "\n",
    "df_h1 = pd.DataFrame({'Participant': list(range(1,41)), 'Coherence': coherenceList0, 'Entropy': entropyList0})\n",
    "\n",
    "df_h1.to_csv('h1_surrogate2_stroop_fp1_fp2.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de82af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mean values for Stroop fp1 and fp2 H1\n",
    "print(\"Mean Coherence: \",np.mean(coherenceList0))\n",
    "print(\"Mean Entropy: \",np.mean(entropyList0))\n",
    "print(\"Mean Rho: \",np.mean(rhoList0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d85249",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for relax data\n",
    "\n",
    "# Define the percentage of data to slide\n",
    "slide_percentage = 0.6\n",
    "\n",
    "# Define a function for data sliding\n",
    "def slide_data(data, slide_percentage):\n",
    "    # Determine the number of data points to slide\n",
    "    num_points_to_slide = int(len(data) * slide_percentage)\n",
    "    \n",
    "    # Slide the data\n",
    "    slid_data = np.roll(data, num_points_to_slide)\n",
    "    \n",
    "    return slid_data\n",
    "\n",
    "surrogate_2_relax_files_fp1 = []\n",
    "surrogate_2_relax_files_fp2 = []\n",
    "\n",
    "for data_fp1 in relax_files_fp1:\n",
    "    slid_data = slide_data(data_fp1.values, slide_percentage)\n",
    "    surrogate_2_relax_files_fp1.append(slid_data)\n",
    "    \n",
    "for data_fp2 in relax_files_fp2:\n",
    "    slid_data = slide_data(data_fp2.values, slide_percentage)\n",
    "    surrogate_2_relax_files_fp2.append(slid_data)\n",
    "    \n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c1ff225",
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate multiSyncPy metrics Relax H1\n",
    "coherenceList0=[]\n",
    "entropyList0=[]\n",
    "rhoList0=[]\n",
    "weakNullList0=[]\n",
    "\n",
    "for i in range(len(surrogate_2_relax_files_fp1)):\n",
    "    print(i)\n",
    "    inputArray = np.array((surrogate_2_relax_files_fp1[i], surrogate_2_relax_files_fp2[i]))\n",
    "    coherence, entropy, rho, weakNull = multiSyncPy_metrics(inputArray)\n",
    "    coherenceList0.append(coherence)\n",
    "    entropyList0.append(entropy)\n",
    "    rhoList0.append(rho)\n",
    "    weakNullList0.append(weakNull)\n",
    "    \n",
    "print('done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e3a9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#round lists\n",
    "\n",
    "rounded_coherence0 = [round(num, 2) for num in coherenceList0]\n",
    "rounded_entropy0 = [round(num, 2) for num in entropyList0]\n",
    "\n",
    "df_h14 = pd.DataFrame({'Participant': list(range(1,41)), 'Coherence': rounded_coherence0, 'Entropy': rounded_entropy0})\n",
    "df_h14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ee519b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert df to csv to compare in H3\n",
    "\n",
    "df_h1 = pd.DataFrame({'Participant': list(range(1,41)), 'Coherence': coherenceList0, 'Entropy': entropyList0})\n",
    "\n",
    "df_h1.to_csv('h1_surrogate2_relax_fp1_fp2.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6ec0727",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mean values for Relax fp1 and fp2 H1\n",
    "print(\"Mean Coherence: \",np.mean(coherenceList0))\n",
    "print(\"Mean Entropy: \",np.mean(entropyList0))\n",
    "print(\"Mean Rho: \",np.mean(rhoList0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23eb1d6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
